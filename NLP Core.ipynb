{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Required Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Anjali\n",
      "[nltk_data]     Sharma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have taken the paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"Thank you all so very much. Thank you to the Academy. Thank you to all of you in this room. \n",
    "            I have to congratulate the other incredible nominees this year. The Revenant was the product of the tireless efforts of an unbelievable cast and crew. \n",
    "            First off, to my brother in this endeavor, Mr. Tom Hardy. Tom, your talent on screen can only be surpassed by your friendship off screen,\n",
    "            thank you for creating a transcendent cinematic experience. Thank you to everybody at Fox and New Regency my entire team. \n",
    "            I have to thank everyone from the very onset of my career … To my parents; \n",
    "            none of this would be possible without you. And to my friends, I love you dearly; you know who you are.\n",
    "\n",
    "            And lastly, I just want to say this: Making The Revenant was about man's relationship to the natural world. \n",
    "            A world that we collectively felt in 2015 as the hottest year in recorded history. Our production needed to move to \n",
    "            the southern tip of this planet just to be able to find snow.Climate change is real, it is happening right now. \n",
    "            It is the most urgent threat facing our entire species, and we need to work collectively together and stop procrastinating. \n",
    "            We need to support leaders around the world who do not speak for the big polluters, but who speak for all of humanity, for the indigenous people of the world, \n",
    "            for the billions and billions of underprivileged people out there who would be most affected by this. For our children’s children, \n",
    "            and for those people out there whose voices have been drowned out by the politics of greed. I thank you all for this amazing award tonight. \n",
    "            Let us not take this planet for granted. I do not take tonight for granted. \n",
    "            Thank you so very much.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use sent_tokenize which return the list of sentences from above paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = nltk.sent_tokenize(paragraph) #tokenize the paragraph into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thank you all so very much.', 'Thank you to the Academy.', 'Thank you to all of you in this room.', 'I have to congratulate the other incredible nominees this year.', 'The Revenant was the product of the tireless efforts of an unbelievable cast and crew.', 'First off, to my brother in this endeavor, Mr. Tom Hardy.', 'Tom, your talent on screen can only be surpassed by your friendship off screen,\\n            thank you for creating a transcendent cinematic experience.', 'Thank you to everybody at Fox and New Regency my entire team.', 'I have to thank everyone from the very onset of my career … To my parents; \\n            none of this would be possible without you.', 'And to my friends, I love you dearly; you know who you are.', \"And lastly, I just want to say this: Making The Revenant was about man's relationship to the natural world.\", 'A world that we collectively felt in 2015 as the hottest year in recorded history.', 'Our production needed to move to \\n            the southern tip of this planet just to be able to find snow.Climate change is real, it is happening right now.', 'It is the most urgent threat facing our entire species, and we need to work collectively together and stop procrastinating.', 'We need to support leaders around the world who do not speak for the big polluters, but who speak for all of humanity, for the indigenous people of the world, \\n            for the billions and billions of underprivileged people out there who would be most affected by this.', 'For our children’s children, \\n            and for those people out there whose voices have been drowned out by the politics of greed.', 'I thank you all for this amazing award tonight.', 'Let us not take this planet for granted.', 'I do not take tonight for granted.', 'Thank you so very much.']\n"
     ]
    }
   ],
   "source": [
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(sentence)) #length of sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use word_tokenize() which tokenize the sentence into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(paragraph) #tokenize the paragraph into word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thank', 'you', 'all', 'so', 'very', 'much', '.', 'Thank', 'you', 'to', 'the', 'Academy', '.', 'Thank', 'you', 'to', 'all', 'of', 'you', 'in', 'this', 'room', '.', 'I', 'have', 'to', 'congratulate', 'the', 'other', 'incredible', 'nominees', 'this', 'year', '.', 'The', 'Revenant', 'was', 'the', 'product', 'of', 'the', 'tireless', 'efforts', 'of', 'an', 'unbelievable', 'cast', 'and', 'crew', '.', 'First', 'off', ',', 'to', 'my', 'brother', 'in', 'this', 'endeavor', ',', 'Mr.', 'Tom', 'Hardy', '.', 'Tom', ',', 'your', 'talent', 'on', 'screen', 'can', 'only', 'be', 'surpassed', 'by', 'your', 'friendship', 'off', 'screen', ',', 'thank', 'you', 'for', 'creating', 'a', 'transcendent', 'cinematic', 'experience', '.', 'Thank', 'you', 'to', 'everybody', 'at', 'Fox', 'and', 'New', 'Regency', 'my', 'entire', 'team', '.', 'I', 'have', 'to', 'thank', 'everyone', 'from', 'the', 'very', 'onset', 'of', 'my', 'career', '…', 'To', 'my', 'parents', ';', 'none', 'of', 'this', 'would', 'be', 'possible', 'without', 'you', '.', 'And', 'to', 'my', 'friends', ',', 'I', 'love', 'you', 'dearly', ';', 'you', 'know', 'who', 'you', 'are', '.', 'And', 'lastly', ',', 'I', 'just', 'want', 'to', 'say', 'this', ':', 'Making', 'The', 'Revenant', 'was', 'about', 'man', \"'s\", 'relationship', 'to', 'the', 'natural', 'world', '.', 'A', 'world', 'that', 'we', 'collectively', 'felt', 'in', '2015', 'as', 'the', 'hottest', 'year', 'in', 'recorded', 'history', '.', 'Our', 'production', 'needed', 'to', 'move', 'to', 'the', 'southern', 'tip', 'of', 'this', 'planet', 'just', 'to', 'be', 'able', 'to', 'find', 'snow.Climate', 'change', 'is', 'real', ',', 'it', 'is', 'happening', 'right', 'now', '.', 'It', 'is', 'the', 'most', 'urgent', 'threat', 'facing', 'our', 'entire', 'species', ',', 'and', 'we', 'need', 'to', 'work', 'collectively', 'together', 'and', 'stop', 'procrastinating', '.', 'We', 'need', 'to', 'support', 'leaders', 'around', 'the', 'world', 'who', 'do', 'not', 'speak', 'for', 'the', 'big', 'polluters', ',', 'but', 'who', 'speak', 'for', 'all', 'of', 'humanity', ',', 'for', 'the', 'indigenous', 'people', 'of', 'the', 'world', ',', 'for', 'the', 'billions', 'and', 'billions', 'of', 'underprivileged', 'people', 'out', 'there', 'who', 'would', 'be', 'most', 'affected', 'by', 'this', '.', 'For', 'our', 'children', '’', 's', 'children', ',', 'and', 'for', 'those', 'people', 'out', 'there', 'whose', 'voices', 'have', 'been', 'drowned', 'out', 'by', 'the', 'politics', 'of', 'greed', '.', 'I', 'thank', 'you', 'all', 'for', 'this', 'amazing', 'award', 'tonight', '.', 'Let', 'us', 'not', 'take', 'this', 'planet', 'for', 'granted', '.', 'I', 'do', 'not', 'take', 'tonight', 'for', 'granted', '.', 'Thank', 'you', 'so', 'very', 'much', '.']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343\n"
     ]
    }
   ],
   "source": [
    "print(len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming And Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming stem the similar words into a word with meaningless .So it takes less time while processing.We can use stemming on that preprocessing analysis where meaning of words are not that much important.\n",
    "\n",
    "While Lemmatization return meaningful word so it take time while processing. We can use stemming on that preprocessing analysis where meaning of words are important.\n"
   ]
  },
  {
   "attachments": {
    "stemmingVsLemma.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![stemmingVsLemma.png](attachment:stemmingVsLemma.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got \"chang\" word after stemming but \"change\" word after Lemmatization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applied Stemming on Paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "sentence = nltk.sent_tokenize(paragraph) #tokenize the paragraph into sentences\n",
    "#stemming\n",
    "\n",
    "for i in range(len(sentence)): #took the length of sentences\n",
    "    words = nltk.word_tokenize(sentence[i]) #tokenize the sentences into word\n",
    "    newwords = [stemmer.stem(word) for word in words]#iterate over the words and found stemming word in newwords\n",
    "    sentence[i] =\" \".join(newwords) # join the all newwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thank you all so veri much .', 'thank you to the academi .', 'thank you to all of you in thi room .', 'I have to congratul the other incred nomine thi year .', 'the reven wa the product of the tireless effort of an unbeliev cast and crew .', 'first off , to my brother in thi endeavor , mr. tom hardi .', 'tom , your talent on screen can onli be surpass by your friendship off screen , thank you for creat a transcend cinemat experi .', 'thank you to everybodi at fox and new regenc my entir team .', 'I have to thank everyon from the veri onset of my career … To my parent ; none of thi would be possibl without you .', 'and to my friend , I love you dearli ; you know who you are .', \"and lastli , I just want to say thi : make the reven wa about man 's relationship to the natur world .\", 'A world that we collect felt in 2015 as the hottest year in record histori .', 'our product need to move to the southern tip of thi planet just to be abl to find snow.clim chang is real , it is happen right now .', 'It is the most urgent threat face our entir speci , and we need to work collect togeth and stop procrastin .', 'We need to support leader around the world who do not speak for the big pollut , but who speak for all of human , for the indigen peopl of the world , for the billion and billion of underprivileg peopl out there who would be most affect by thi .', 'for our children ’ s children , and for those peopl out there whose voic have been drown out by the polit of greed .', 'I thank you all for thi amaz award tonight .', 'let us not take thi planet for grant .', 'I do not take tonight for grant .', 'thank you so veri much .']\n"
     ]
    }
   ],
   "source": [
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applied Lemmatizer on Paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = nltk.sent_tokenize(paragraph) # tokenize the paragraph into sentences\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#lemmatizing\n",
    "for i in range(len(sentence)): #took all the sentences\n",
    "    words = nltk.word_tokenize(sentence[i]) # did word tokenization of each of sentences\n",
    "    newwords = [lemmatizer.lemmatize(word) for word in words] #lemmatize the word into newwords\n",
    "    sentence[i]=\" \".join(newwords) #join the newwords into sentence list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thank you all so very much .', 'Thank you to the Academy .', 'Thank you to all of you in this room .', 'I have to congratulate the other incredible nominee this year .', 'The Revenant wa the product of the tireless effort of an unbelievable cast and crew .', 'First off , to my brother in this endeavor , Mr. Tom Hardy .', 'Tom , your talent on screen can only be surpassed by your friendship off screen , thank you for creating a transcendent cinematic experience .', 'Thank you to everybody at Fox and New Regency my entire team .', 'I have to thank everyone from the very onset of my career … To my parent ; none of this would be possible without you .', 'And to my friend , I love you dearly ; you know who you are .', \"And lastly , I just want to say this : Making The Revenant wa about man 's relationship to the natural world .\", 'A world that we collectively felt in 2015 a the hottest year in recorded history .', 'Our production needed to move to the southern tip of this planet just to be able to find snow.Climate change is real , it is happening right now .', 'It is the most urgent threat facing our entire specie , and we need to work collectively together and stop procrastinating .', 'We need to support leader around the world who do not speak for the big polluter , but who speak for all of humanity , for the indigenous people of the world , for the billion and billion of underprivileged people out there who would be most affected by this .', 'For our child ’ s child , and for those people out there whose voice have been drowned out by the politics of greed .', 'I thank you all for this amazing award tonight .', 'Let u not take this planet for granted .', 'I do not take tonight for granted .', 'Thank you so very much .']\n"
     ]
    }
   ],
   "source": [
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopword Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a such important step for text preprocessing. It will remove the words like is,am,or,not etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(sentence)):\n",
    "    words = nltk.word_tokenize(sentence[i])\n",
    "    newwords = [word for word in words if word not in stopwords.words('english')]\n",
    "    sentence[i] = \" \".join(newwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thank much .', 'Thank Academy .', 'Thank room .', 'I congratulate incredible nominee year .', 'The Revenant wa product tireless effort unbelievable cast crew .', 'First , brother endeavor , Mr. Tom Hardy .', 'Tom , talent screen surpassed friendship screen , thank creating transcendent cinematic experience .', 'Thank everybody Fox New Regency entire team .', 'I thank everyone onset career … To parent ; none would possible without .', 'And friend , I love dearly ; know .', \"And lastly , I want say : Making The Revenant wa man 's relationship natural world .\", 'A world collectively felt 2015 hottest year recorded history .', 'Our production needed move southern tip planet able find snow.Climate change real , happening right .', 'It urgent threat facing entire specie , need work collectively together stop procrastinating .', 'We need support leader around world speak big polluter , speak humanity , indigenous people world , billion billion underprivileged people would affected .', 'For child ’ child , people whose voice drowned politics greed .', 'I thank amazing award tonight .', 'Let u take planet granted .', 'I take tonight granted .', 'Thank much .']\n"
     ]
    }
   ],
   "source": [
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to find part of speech for different-2 word in above sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(paragraph)\n",
    "tagged_word = nltk.pos_tag(words)\n",
    "word_tag = []\n",
    "for i in tagged_word:\n",
    "    word_tag.append(i[0]+\"_\"+i[1])\n",
    "tagged_paragraph = \" \".join(word_tag)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank_NNP you_PRP all_DT so_RB very_RB much_JJ ._. Thank_VB you_PRP to_TO the_DT Academy_NNP ._. Thank_NNP you_PRP to_TO all_DT of_IN you_PRP in_IN this_DT room_NN ._. I_PRP have_VBP to_TO congratulate_VB the_DT other_JJ incredible_JJ nominees_NNS this_DT year_NN ._. The_DT Revenant_NNP was_VBD the_DT product_NN of_IN the_DT tireless_NN efforts_NNS of_IN an_DT unbelievable_JJ cast_NN and_CC crew_NN ._. First_NNP off_RB ,_, to_TO my_PRP$ brother_NN in_IN this_DT endeavor_NN ,_, Mr._NNP Tom_NNP Hardy_NNP ._. Tom_NNP ,_, your_PRP$ talent_NN on_IN screen_NN can_MD only_RB be_VB surpassed_VBN by_IN your_PRP$ friendship_NN off_IN screen_NN ,_, thank_NN you_PRP for_IN creating_VBG a_DT transcendent_JJ cinematic_JJ experience_NN ._. Thank_NNP you_PRP to_TO everybody_VB at_IN Fox_NNP and_CC New_NNP Regency_NNP my_PRP$ entire_JJ team_NN ._. I_PRP have_VBP to_TO thank_VB everyone_NN from_IN the_DT very_RB onset_NN of_IN my_PRP$ career_NN …_NN To_TO my_PRP$ parents_NNS ;_: none_NN of_IN this_DT would_MD be_VB possible_JJ without_IN you_PRP ._. And_CC to_TO my_PRP$ friends_NNS ,_, I_PRP love_VBP you_PRP dearly_RB ;_: you_PRP know_VBP who_WP you_PRP are_VBP ._. And_CC lastly_RB ,_, I_PRP just_RB want_VBP to_TO say_VB this_DT :_: Making_VBG The_DT Revenant_NNP was_VBD about_IN man_NN 's_POS relationship_NN to_TO the_DT natural_JJ world_NN ._. A_DT world_NN that_IN we_PRP collectively_RB felt_VBD in_IN 2015_CD as_IN the_DT hottest_JJS year_NN in_IN recorded_JJ history_NN ._. Our_PRP$ production_NN needed_VBN to_TO move_VB to_TO the_DT southern_JJ tip_NN of_IN this_DT planet_NN just_RB to_TO be_VB able_JJ to_TO find_VB snow.Climate_JJ change_NN is_VBZ real_JJ ,_, it_PRP is_VBZ happening_VBG right_RB now_RB ._. It_PRP is_VBZ the_DT most_RBS urgent_JJ threat_NN facing_VBG our_PRP$ entire_JJ species_NNS ,_, and_CC we_PRP need_VBP to_TO work_VB collectively_RB together_RB and_CC stop_VB procrastinating_NN ._. We_PRP need_VBP to_TO support_VB leaders_NNS around_IN the_DT world_NN who_WP do_VBP not_RB speak_VB for_IN the_DT big_JJ polluters_NNS ,_, but_CC who_WP speak_VBP for_IN all_DT of_IN humanity_NN ,_, for_IN the_DT indigenous_JJ people_NNS of_IN the_DT world_NN ,_, for_IN the_DT billions_NNS and_CC billions_NNS of_IN underprivileged_JJ people_NNS out_IN there_EX who_WP would_MD be_VB most_RBS affected_VBN by_IN this_DT ._. For_IN our_PRP$ children_NNS ’_VBP s_JJ children_NNS ,_, and_CC for_IN those_DT people_NNS out_RP there_RB whose_WP$ voices_NNS have_VBP been_VBN drowned_VBN out_RP by_IN the_DT politics_NNS of_IN greed_NN ._. I_PRP thank_VBP you_PRP all_DT for_IN this_DT amazing_JJ award_NN tonight_NN ._. Let_VB us_PRP not_RB take_VB this_DT planet_NN for_IN granted_VBN ._. I_PRP do_VBP not_RB take_VB tonight_NN for_IN granted_VBN ._. Thank_NNP you_PRP so_RB very_RB much_JJ ._.\n"
     ]
    }
   ],
   "source": [
    "print(tagged_paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS Tag Meanings : Here are the meanings of the Parts-Of-Speech tags used in NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "CC - Coordinating conjunction\n",
    "\n",
    "CD - Cardinal number\n",
    "\n",
    "DT - Determiner\n",
    "\n",
    "EX - Existential there\n",
    "\n",
    "FW - Foreign word\n",
    "\n",
    "IN - Preposition or subordinating conjunction\n",
    "\n",
    "JJ - Adjective\n",
    "\n",
    "JJR - Adjective, comparative\n",
    "\n",
    "JJS - Adjective, superlative\n",
    "\n",
    "LS - List item marker\n",
    "\n",
    "MD - Modal\n",
    "\n",
    "NN - Noun, singular or mass\n",
    "\n",
    "NNS - Noun, plural\n",
    "\n",
    "NNP - Proper noun, singular\n",
    "\n",
    "NNPS - Proper noun, plural\n",
    "\n",
    "PDT - Predeterminer\n",
    "\n",
    "POS - Possessive ending\n",
    "\n",
    "PRP - Personal pronoun\n",
    "\n",
    "PRP$ - Possessive pronoun\n",
    "\n",
    "RB - Adverb\n",
    "\n",
    "RBR - Adverb, comparative\n",
    "\n",
    "RBS - Adverb, superlative\n",
    "\n",
    "RP - Particle\n",
    "\n",
    "SYM - Symbol\n",
    "\n",
    "TO - to\n",
    "\n",
    "UH - Interjection\n",
    "\n",
    "VB - Verb, base form\n",
    "\n",
    "VBD - Verb, past tense\n",
    "\n",
    "VBG - Verb, gerund or present participle\n",
    "\n",
    "VBN - Verb, past participle\n",
    "\n",
    "VBP - Verb, non-3rd person singular present\n",
    "\n",
    "VBZ - Verb, 3rd person singular present\n",
    "\n",
    "WDT - Wh-determiner\n",
    "\n",
    "WP - Wh-pronoun\n",
    "\n",
    "WP$ -- Possessive wh-pronoun\n",
    "\n",
    "WRB - Wh-adverb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = nltk.sent_tokenize(paragraph)\n",
    "for i in range(len(dataset)):\n",
    "    dataset[i] = dataset[i].lower() # converted all the words in lower cae\n",
    "    dataset[i] = re.sub(r'\\W',' ',dataset[i]) #replace non-word by space\n",
    "    dataset[i] = re.sub(r'\\s+',' ',dataset[i]) # replace the all space by single space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thank you all so very much ', 'thank you to the academy ', 'thank you to all of you in this room ', 'i have to congratulate the other incredible nominees this year ', 'the revenant was the product of the tireless efforts of an unbelievable cast and crew ', 'first off to my brother in this endeavor mr tom hardy ', 'tom your talent on screen can only be surpassed by your friendship off screen thank you for creating a transcendent cinematic experience ', 'thank you to everybody at fox and new regency my entire team ', 'i have to thank everyone from the very onset of my career to my parents none of this would be possible without you ', 'and to my friends i love you dearly you know who you are ', 'and lastly i just want to say this making the revenant was about man s relationship to the natural world ', 'a world that we collectively felt in 2015 as the hottest year in recorded history ', 'our production needed to move to the southern tip of this planet just to be able to find snow climate change is real it is happening right now ', 'it is the most urgent threat facing our entire species and we need to work collectively together and stop procrastinating ', 'we need to support leaders around the world who do not speak for the big polluters but who speak for all of humanity for the indigenous people of the world for the billions and billions of underprivileged people out there who would be most affected by this ', 'for our children s children and for those people out there whose voices have been drowned out by the politics of greed ', 'i thank you all for this amazing award tonight ', 'let us not take this planet for granted ', 'i do not take tonight for granted ', 'thank you so very much ']\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create histogram\n",
    "word2count = {}\n",
    "for data in dataset: # here data returns the list of sentence\n",
    "    words = nltk.word_tokenize(data)#tokenize the list of sentences into words\n",
    "    for word in words: # using for loop, we are taking each word from words\n",
    "        if word not in word2count.keys(): # if word is not in word2count set then we are counting as first word\n",
    "            word2count[word] = 1 # and setting as 1\n",
    "        else:\n",
    "            word2count[word] += 1 # if word is already contain in word2count then we are increasing the word occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'thank': 8, 'you': 12, 'all': 4, 'so': 2, 'very': 3, 'much': 2, 'to': 16, 'the': 17, 'academy': 1, 'of': 10, 'in': 4, 'this': 9, 'room': 1, 'i': 6, 'have': 3, 'congratulate': 1, 'other': 1, 'incredible': 1, 'nominees': 1, 'year': 2, 'revenant': 2, 'was': 2, 'product': 1, 'tireless': 1, 'efforts': 1, 'an': 1, 'unbelievable': 1, 'cast': 1, 'and': 8, 'crew': 1, 'first': 1, 'off': 2, 'my': 5, 'brother': 1, 'endeavor': 1, 'mr': 1, 'tom': 2, 'hardy': 1, 'your': 2, 'talent': 1, 'on': 1, 'screen': 2, 'can': 1, 'only': 1, 'be': 4, 'surpassed': 1, 'by': 3, 'friendship': 1, 'for': 10, 'creating': 1, 'a': 2, 'transcendent': 1, 'cinematic': 1, 'experience': 1, 'everybody': 1, 'at': 1, 'fox': 1, 'new': 1, 'regency': 1, 'entire': 2, 'team': 1, 'everyone': 1, 'from': 1, 'onset': 1, 'career': 1, 'parents': 1, 'none': 1, 'would': 2, 'possible': 1, 'without': 1, 'friends': 1, 'love': 1, 'dearly': 1, 'know': 1, 'who': 4, 'are': 1, 'lastly': 1, 'just': 2, 'want': 1, 'say': 1, 'making': 1, 'about': 1, 'man': 1, 's': 2, 'relationship': 1, 'natural': 1, 'world': 4, 'that': 1, 'we': 3, 'collectively': 2, 'felt': 1, '2015': 1, 'as': 1, 'hottest': 1, 'recorded': 1, 'history': 1, 'our': 3, 'production': 1, 'needed': 1, 'move': 1, 'southern': 1, 'tip': 1, 'planet': 2, 'able': 1, 'find': 1, 'snow': 1, 'climate': 1, 'change': 1, 'is': 3, 'real': 1, 'it': 2, 'happening': 1, 'right': 1, 'now': 1, 'most': 2, 'urgent': 1, 'threat': 1, 'facing': 1, 'species': 1, 'need': 2, 'work': 1, 'together': 1, 'stop': 1, 'procrastinating': 1, 'support': 1, 'leaders': 1, 'around': 1, 'do': 2, 'not': 3, 'speak': 2, 'big': 1, 'polluters': 1, 'but': 1, 'humanity': 1, 'indigenous': 1, 'people': 3, 'billions': 2, 'underprivileged': 1, 'out': 3, 'there': 2, 'affected': 1, 'children': 2, 'those': 1, 'whose': 1, 'voices': 1, 'been': 1, 'drowned': 1, 'politics': 1, 'greed': 1, 'amazing': 1, 'award': 1, 'tonight': 2, 'let': 1, 'us': 1, 'take': 2, 'granted': 2}\n"
     ]
    }
   ],
   "source": [
    "print(word2count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_words = heapq.nlargest(100,word2count,key = word2count.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'to', 'you', 'of', 'for', 'this', 'thank', 'and', 'i', 'my', 'all', 'in', 'be', 'who', 'world', 'very', 'have', 'by', 'we', 'our', 'is', 'not', 'people', 'out', 'so', 'much', 'year', 'revenant', 'was', 'off', 'tom', 'your', 'screen', 'a', 'entire', 'would', 'just', 's', 'collectively', 'planet', 'it', 'most', 'need', 'do', 'speak', 'billions', 'there', 'children', 'tonight', 'take', 'granted', 'academy', 'room', 'congratulate', 'other', 'incredible', 'nominees', 'product', 'tireless', 'efforts', 'an', 'unbelievable', 'cast', 'crew', 'first', 'brother', 'endeavor', 'mr', 'hardy', 'talent', 'on', 'can', 'only', 'surpassed', 'friendship', 'creating', 'transcendent', 'cinematic', 'experience', 'everybody', 'at', 'fox', 'new', 'regency', 'team', 'everyone', 'from', 'onset', 'career', 'parents', 'none', 'possible', 'without', 'friends', 'love', 'dearly', 'know', 'are', 'lastly', 'want']\n"
     ]
    }
   ],
   "source": [
    "print(freq_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for data in dataset:\n",
    "    vector = []\n",
    "    for word in freq_words:\n",
    "        #print(word)\n",
    "        if word in nltk.word_tokenize(data):\n",
    "            vector.append(1)\n",
    "        else:\n",
    "            vector.append(0)\n",
    "    X.append(vector)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0], [1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found the result as list of list. We need to convet it into 2D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# got the bag of words matrix\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF stands for \"Term Frequency\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formula :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF : (Number of occurrences of a word in the document)/(total number of word in that document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"to be or not to be\" if we calculate TF for word to,be,or then \n",
    " 1. for \"to\" = 2/6 = 0.33\n",
    " 2. for \"be\" = 2/6 = 0.33\n",
    " 3. for \"or\" = 1/6 = 0.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDF stands for Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formula:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDF = loge(Number of documents)/(Number of documents containing word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doc1 : \"to be or not to be\"\n",
    "\n",
    "doc2 : i have to be\n",
    "\n",
    "doc3 : you got to be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. IDF for word \"to\" = log(e)(3/3) = 0\n",
    "2. IDF for word \"be\" = log(e)(3/3) = 0\n",
    "3. IDF for word \"or\" = log(e)(3/1) = 0.477"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_idfs = {} # take a sets word_idfs\n",
    "for word in freq_words: # take each word from freq_words\n",
    "    doc_count = 0\n",
    "    for data in dataset: # take the each sentences from dataset\n",
    "        words = nltk.word_tokenize(data)# coverted to word_tokenize\n",
    "        if word in words:#check the frequent word from words if it ? we are counting 1\n",
    "            doc_count += 1 \n",
    "    word_idfs[word] = np.log(len(dataset)/doc_count+1)#calculating the IDF values for each frequent words        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1.0986122886681098, 'to': 1.0360919316867758, 'you': 1.1700712526502546, 'of': 1.4663370687934272, 'for': 1.4663370687934272, 'this': 1.1700712526502546, 'thank': 1.252762968495368, 'and': 1.349926716949016, 'i': 1.4663370687934272, 'my': 1.791759469228055, 'all': 1.791759469228055, 'in': 2.03688192726104, 'be': 1.791759469228055, 'who': 2.3978952727983707, 'world': 2.03688192726104, 'very': 2.03688192726104, 'have': 2.03688192726104, 'by': 2.03688192726104, 'we': 2.03688192726104, 'our': 2.03688192726104, 'is': 2.3978952727983707, 'not': 2.03688192726104, 'people': 2.3978952727983707, 'out': 2.3978952727983707, 'so': 2.3978952727983707, 'much': 2.3978952727983707, 'year': 2.3978952727983707, 'revenant': 2.3978952727983707, 'was': 2.3978952727983707, 'off': 2.3978952727983707, 'tom': 2.3978952727983707, 'your': 3.044522437723423, 'screen': 3.044522437723423, 'a': 2.3978952727983707, 'entire': 2.3978952727983707, 'would': 2.3978952727983707, 'just': 2.3978952727983707, 's': 2.3978952727983707, 'collectively': 2.3978952727983707, 'planet': 2.3978952727983707, 'it': 2.3978952727983707, 'most': 2.3978952727983707, 'need': 2.3978952727983707, 'do': 2.3978952727983707, 'speak': 3.044522437723423, 'billions': 3.044522437723423, 'there': 2.3978952727983707, 'children': 3.044522437723423, 'tonight': 2.3978952727983707, 'take': 2.3978952727983707, 'granted': 2.3978952727983707, 'academy': 3.044522437723423, 'room': 3.044522437723423, 'congratulate': 3.044522437723423, 'other': 3.044522437723423, 'incredible': 3.044522437723423, 'nominees': 3.044522437723423, 'product': 3.044522437723423, 'tireless': 3.044522437723423, 'efforts': 3.044522437723423, 'an': 3.044522437723423, 'unbelievable': 3.044522437723423, 'cast': 3.044522437723423, 'crew': 3.044522437723423, 'first': 3.044522437723423, 'brother': 3.044522437723423, 'endeavor': 3.044522437723423, 'mr': 3.044522437723423, 'hardy': 3.044522437723423, 'talent': 3.044522437723423, 'on': 3.044522437723423, 'can': 3.044522437723423, 'only': 3.044522437723423, 'surpassed': 3.044522437723423, 'friendship': 3.044522437723423, 'creating': 3.044522437723423, 'transcendent': 3.044522437723423, 'cinematic': 3.044522437723423, 'experience': 3.044522437723423, 'everybody': 3.044522437723423, 'at': 3.044522437723423, 'fox': 3.044522437723423, 'new': 3.044522437723423, 'regency': 3.044522437723423, 'team': 3.044522437723423, 'everyone': 3.044522437723423, 'from': 3.044522437723423, 'onset': 3.044522437723423, 'career': 3.044522437723423, 'parents': 3.044522437723423, 'none': 3.044522437723423, 'possible': 3.044522437723423, 'without': 3.044522437723423, 'friends': 3.044522437723423, 'love': 3.044522437723423, 'dearly': 3.044522437723423, 'know': 3.044522437723423, 'are': 3.044522437723423, 'lastly': 3.044522437723423, 'want': 3.044522437723423}\n"
     ]
    }
   ],
   "source": [
    "print(word_idfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF - Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_matrix = {}\n",
    "for word in freq_words:\n",
    "    doc_tf = []\n",
    "    for data in dataset:\n",
    "        frequency = 0\n",
    "        for w in nltk.word_tokenize(data):\n",
    "            if word==w:\n",
    "                frequency+=1\n",
    "        tf_words = frequency/(len(nltk.word_tokenize(data)))        \n",
    "        doc_tf.append(tf_words)\n",
    "    tf_matrix[word] = doc_tf   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': [0.0, 0.2, 0.0, 0.1, 0.2, 0.0, 0.0, 0.0, 0.043478260869565216, 0.0, 0.1, 0.06666666666666667, 0.03571428571428571, 0.05, 0.10638297872340426, 0.045454545454545456, 0.0, 0.0, 0.0, 0.0], 'to': [0.0, 0.2, 0.1111111111111111, 0.1, 0.0, 0.09090909090909091, 0.0, 0.08333333333333333, 0.08695652173913043, 0.07692307692307693, 0.1, 0.0, 0.14285714285714285, 0.05, 0.02127659574468085, 0.0, 0.0, 0.0, 0.0, 0.0], 'you': [0.16666666666666666, 0.2, 0.2222222222222222, 0.0, 0.0, 0.0, 0.045454545454545456, 0.08333333333333333, 0.043478260869565216, 0.23076923076923078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1111111111111111, 0.0, 0.0, 0.2], 'of': [0.0, 0.0, 0.1111111111111111, 0.0, 0.13333333333333333, 0.0, 0.0, 0.0, 0.08695652173913043, 0.0, 0.0, 0.0, 0.03571428571428571, 0.0, 0.06382978723404255, 0.045454545454545456, 0.0, 0.0, 0.0, 0.0], 'for': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0851063829787234, 0.09090909090909091, 0.1111111111111111, 0.125, 0.14285714285714285, 0.0], 'this': [0.0, 0.0, 0.1111111111111111, 0.1, 0.0, 0.09090909090909091, 0.0, 0.0, 0.043478260869565216, 0.0, 0.05, 0.0, 0.03571428571428571, 0.0, 0.02127659574468085, 0.0, 0.1111111111111111, 0.125, 0.0, 0.0], 'thank': [0.16666666666666666, 0.2, 0.1111111111111111, 0.0, 0.0, 0.0, 0.045454545454545456, 0.08333333333333333, 0.043478260869565216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1111111111111111, 0.0, 0.0, 0.2], 'and': [0.0, 0.0, 0.0, 0.0, 0.06666666666666667, 0.0, 0.0, 0.08333333333333333, 0.0, 0.07692307692307693, 0.05, 0.0, 0.0, 0.1, 0.02127659574468085, 0.045454545454545456, 0.0, 0.0, 0.0, 0.0], 'i': [0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.043478260869565216, 0.07692307692307693, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1111111111111111, 0.0, 0.14285714285714285, 0.0], 'my': [0.0, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 0.0, 0.08333333333333333, 0.08695652173913043, 0.07692307692307693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'all': [0.16666666666666666, 0.0, 0.1111111111111111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02127659574468085, 0.0, 0.1111111111111111, 0.0, 0.0, 0.0], 'in': [0.0, 0.0, 0.1111111111111111, 0.0, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'be': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045454545454545456, 0.0, 0.043478260869565216, 0.0, 0.0, 0.0, 0.03571428571428571, 0.0, 0.02127659574468085, 0.0, 0.0, 0.0, 0.0, 0.0], 'who': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07692307692307693, 0.0, 0.0, 0.0, 0.0, 0.06382978723404255, 0.0, 0.0, 0.0, 0.0, 0.0], 'world': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05, 0.06666666666666667, 0.0, 0.0, 0.0425531914893617, 0.0, 0.0, 0.0, 0.0, 0.0], 'very': [0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043478260869565216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2], 'have': [0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.043478260869565216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.0], 'by': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02127659574468085, 0.045454545454545456, 0.0, 0.0, 0.0, 0.0], 'we': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06666666666666667, 0.0, 0.05, 0.02127659574468085, 0.0, 0.0, 0.0, 0.0, 0.0], 'our': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03571428571428571, 0.05, 0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.0], 'is': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07142857142857142, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'not': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02127659574468085, 0.0, 0.0, 0.125, 0.14285714285714285, 0.0], 'people': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0425531914893617, 0.045454545454545456, 0.0, 0.0, 0.0, 0.0], 'out': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02127659574468085, 0.09090909090909091, 0.0, 0.0, 0.0, 0.0], 'so': [0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2], 'much': [0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2], 'year': [0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06666666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'revenant': [0.0, 0.0, 0.0, 0.0, 0.06666666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'was': [0.0, 0.0, 0.0, 0.0, 0.06666666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'off': [0.0, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 0.045454545454545456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'tom': [0.0, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 0.045454545454545456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'your': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'screen': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'a': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.0, 0.06666666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'entire': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'would': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043478260869565216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02127659574468085, 0.0, 0.0, 0.0, 0.0, 0.0], 'just': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05, 0.0, 0.03571428571428571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 's': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.0], 'collectively': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06666666666666667, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'planet': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03571428571428571, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0], 'it': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03571428571428571, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'most': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05, 0.02127659574468085, 0.0, 0.0, 0.0, 0.0, 0.0], 'need': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05, 0.02127659574468085, 0.0, 0.0, 0.0, 0.0, 0.0], 'do': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02127659574468085, 0.0, 0.0, 0.0, 0.14285714285714285, 0.0], 'speak': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0425531914893617, 0.0, 0.0, 0.0, 0.0, 0.0], 'billions': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0425531914893617, 0.0, 0.0, 0.0, 0.0, 0.0], 'there': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02127659574468085, 0.045454545454545456, 0.0, 0.0, 0.0, 0.0], 'children': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0, 0.0], 'tonight': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1111111111111111, 0.0, 0.14285714285714285, 0.0], 'take': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.14285714285714285, 0.0], 'granted': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.14285714285714285, 0.0], 'academy': [0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'room': [0.0, 0.0, 0.1111111111111111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'congratulate': [0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'other': [0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'incredible': [0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'nominees': [0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'product': [0.0, 0.0, 0.0, 0.0, 0.06666666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'tireless': [0.0, 0.0, 0.0, 0.0, 0.06666666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'efforts': [0.0, 0.0, 0.0, 0.0, 0.06666666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'an': [0.0, 0.0, 0.0, 0.0, 0.06666666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'unbelievable': [0.0, 0.0, 0.0, 0.0, 0.06666666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'cast': [0.0, 0.0, 0.0, 0.0, 0.06666666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'crew': [0.0, 0.0, 0.0, 0.0, 0.06666666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'first': [0.0, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'brother': [0.0, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'endeavor': [0.0, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'mr': [0.0, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'hardy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'talent': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'on': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'can': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'only': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'surpassed': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'friendship': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'creating': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'transcendent': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'cinematic': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'experience': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045454545454545456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'everybody': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'at': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'fox': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'new': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'regency': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'team': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'everyone': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043478260869565216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'from': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043478260869565216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'onset': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043478260869565216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'career': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043478260869565216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'parents': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043478260869565216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'none': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043478260869565216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'possible': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043478260869565216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'without': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043478260869565216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'friends': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07692307692307693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'love': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07692307692307693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'dearly': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07692307692307693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'know': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07692307692307693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'are': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07692307692307693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'lastly': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'want': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n"
     ]
    }
   ],
   "source": [
    "print(tf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF- IDF will be multiplication of TF and IDF values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = []\n",
    "for word in tf_matrix.keys():\n",
    "    tf_idf = []\n",
    "    for value in tf_matrix[word]:\n",
    "        score = value*word_idfs[word]\n",
    "        tf_idf.append(score)\n",
    "    tfidf_matrix.append(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 0.21972245773362198, 0.0, 0.10986122886681099, 0.21972245773362198, 0.0, 0.0, 0.0, 0.047765751681222164, 0.0, 0.10986122886681099, 0.07324081924454065, 0.039236153166718205, 0.054930614433405495, 0.11687364773064998, 0.04993692221218681, 0.0, 0.0, 0.0, 0.0], [0.0, 0.20721838633735518, 0.11512132574297508, 0.10360919316867759, 0.0, 0.09419017560788871, 0.0, 0.08634099430723131, 0.09009495058145876, 0.07969937936052122, 0.10360919316867759, 0.0, 0.14801313309811082, 0.051804596584338794, 0.022044509184825017, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1950118754417091, 0.23401425053005093, 0.2600158339222788, 0.0, 0.0, 0.0, 0.05318505693864794, 0.09750593772085454, 0.05087266315870672, 0.27001644291928956, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1300079169611394, 0.0, 0.0, 0.23401425053005093], [0.0, 0.0, 0.16292634097704745, 0.0, 0.19551160917245697, 0.0, 0.0, 0.0, 0.12750757119942846, 0.0, 0.0, 0.0, 0.05236918102833668, 0.0, 0.09359598311447406, 0.06665168494515578, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06665168494515578, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1247946441526321, 0.13330336989031155, 0.16292634097704745, 0.1832921335991784, 0.20947672411334672, 0.0], [0.0, 0.0, 0.1300079169611394, 0.11700712526502546, 0.0, 0.10637011387729588, 0.0, 0.0, 0.05087266315870672, 0.0, 0.05850356263251273, 0.0, 0.041788259023223376, 0.0, 0.0248951330351118, 0.0, 0.1300079169611394, 0.14625890658128182, 0.0, 0.0], [0.20879382808256133, 0.2505525936990736, 0.1391958853883742, 0.0, 0.0, 0.0, 0.05694377129524401, 0.10439691404128067, 0.05446795515197252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1391958853883742, 0.0, 0.0, 0.2505525936990736], [0.0, 0.0, 0.0, 0.0, 0.08999511446326773, 0.0, 0.0, 0.11249389307908465, 0.0, 0.10384051668838584, 0.0674963358474508, 0.0, 0.0, 0.1349926716949016, 0.028721845041468422, 0.06136030531586436, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.1466337068793427, 0.0, 0.0, 0.0, 0.0, 0.06375378559971423, 0.11279515913795594, 0.07331685343967136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16292634097704745, 0.0, 0.20947672411334672, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.16288722447527773, 0.0, 0.1493132891023379, 0.15580517123722218, 0.13782765147908116, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2986265782046758, 0.0, 0.19908438546978388, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03812254189846925, 0.0, 0.19908438546978388, 0.0, 0.0, 0.0], [0.0, 0.0, 0.22632021414011555, 0.0, 0.0, 0.1851710842964582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2715842569681387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08144361223763887, 0.0, 0.07790258561861109, 0.0, 0.0, 0.0, 0.06399140961528767, 0.0, 0.03812254189846925, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1844534825229516, 0.0, 0.0, 0.0, 0.0, 0.15305714507223642, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10184409636305201, 0.13579212848406935, 0.0, 0.0, 0.08667582669195915, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33948032121017335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08856008379395826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.40737638545220806], [0.0, 0.0, 0.0, 0.20368819272610403, 0.0, 0.0, 0.0, 0.0, 0.08856008379395826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0925855421482291, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0925855421482291, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04333791334597958, 0.0925855421482291, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13579212848406935, 0.0, 0.10184409636305201, 0.04333791334597958, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07274578311646572, 0.10184409636305201, 0.0, 0.0925855421482291, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17127823377131218, 0.11989476363991854, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04333791334597958, 0.0, 0.0, 0.25461024090763, 0.2909831324658629, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10203809671482428, 0.10899523967265322, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05101904835741214, 0.21799047934530644, 0.0, 0.0, 0.0, 0.0], [0.39964921213306176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47957905455967414], [0.39964921213306176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47957905455967414], [0.0, 0.0, 0.0, 0.23978952727983707, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15985968485322471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.15985968485322471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11989476363991854, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.15985968485322471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11989476363991854, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.21799047934530644, 0.10899523967265322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.21799047934530644, 0.10899523967265322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27677476706576576, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27677476706576576, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10899523967265322, 0.0, 0.0, 0.0, 0.0, 0.15985968485322471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19982460606653088, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11989476363991854, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10425631620862481, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05101904835741214, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11989476363991854, 0.0, 0.08563911688565609, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11989476363991854, 0.0, 0.0, 0.0, 0.0, 0.10899523967265322, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15985968485322471, 0.0, 0.11989476363991854, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08563911688565609, 0.0, 0.0, 0.0, 0.0, 0.29973690909979633, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08563911688565609, 0.11989476363991854, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11989476363991854, 0.05101904835741214, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11989476363991854, 0.05101904835741214, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05101904835741214, 0.0, 0.0, 0.0, 0.34255646754262437, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1295541462861031, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1295541462861031, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05101904835741214, 0.10899523967265322, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27677476706576576, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26643280808870784, 0.0, 0.34255646754262437, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29973690909979633, 0.34255646754262437, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29973690909979633, 0.34255646754262437, 0.0], [0.0, 0.6089044875446846, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.3382802708581581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.3044522437723423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.3044522437723423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.3044522437723423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.3044522437723423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.20296816251489486, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.20296816251489486, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.20296816251489486, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.20296816251489486, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.20296816251489486, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.20296816251489486, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.20296816251489486, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.27677476706576576, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.27677476706576576, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.27677476706576576, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.27677476706576576, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.27677476706576576, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13838738353288288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13838738353288288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13838738353288288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13838738353288288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13838738353288288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13838738353288288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13838738353288288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13838738353288288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13838738353288288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13838738353288288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2537102031436186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2537102031436186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2537102031436186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2537102031436186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2537102031436186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2537102031436186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1323705407705836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1323705407705836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1323705407705836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1323705407705836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1323705407705836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1323705407705836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1323705407705836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1323705407705836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23419403367103256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23419403367103256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23419403367103256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23419403367103256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23419403367103256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15222612188617116, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15222612188617116, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = np.asarray(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.21972246 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.20721839 0.11512133 ... 0.         0.         0.        ]\n",
      " [0.19501188 0.23401425 0.26001583 ... 0.         0.         0.23401425]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 20)\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = np.transpose(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.19501188 ... 0.         0.         0.        ]\n",
      " [0.21972246 0.20721839 0.23401425 ... 0.         0.         0.        ]\n",
      " [0.         0.11512133 0.26001583 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.23401425 ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Gram Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"he term is frequently used interchangeably with the term climate change, though the latter refers to \n",
    "          both human- and naturally produced warming and the effects it has on our planet. \n",
    "          It is most commonly measured as the average increase in Earth’s global surface temperature.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n= 2\n",
    "ngrams = {}\n",
    "for i in range(len(text)-n):\n",
    "    gram = text[i:i+n] # text[0:3]\n",
    "    if gram not in ngrams.keys():\n",
    "        ngrams[gram] = []\n",
    "    ngrams[gram].append(text[i+n])    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'he': [' ', ' ', ' ', ' ', ' '], 'e ': ['t', 't', 'c', 'l', 'e', 'a', 'i', 'i', 't'], ' t': ['e', 'h', 'e', 'h', 'h', 'o', 'h', 'h', 'e'], 'te': ['r', 'r', 'r', ' ', 'r', 'm'], 'er': ['m', 'c', 'm', ' ', 's', 'a', 'a'], 'rm': [' ', ' ', 'i'], 'm ': ['i', 'c'], ' i': ['s', 'n', 't', 's', 'n', 'n'], 'is': [' ', ' '], 's ': ['f', 't', 'i', 'o', 'm', 't', 'g'], ' f': ['r'], 'fr': ['e'], 're': ['q', 'f', 'd', 'a', '.'], 'eq': ['u'], 'qu': ['e'], 'ue': ['n'], 'en': ['t'], 'nt': ['l', 'e'], 'tl': ['y'], 'ly': [' ', ' ', ' ', ' '], 'y ': ['u', 'w', 'p', 'm'], ' u': ['s'], 'us': ['e'], 'se': ['d', ' '], 'ed': [' ', ' ', ' '], 'd ': ['i', 'n', 'w', 't', 'a'], 'in': ['t', 'g', 'c', ' '], 'rc': ['h'], 'ch': ['a', 'a'], 'ha': ['n', 'n', 's'], 'an': ['g', 'g', '-', 'd', 'd', 'e'], 'ng': ['e', 'e', ' '], 'ge': ['a', ',', ' '], 'ea': ['b', 's', 's'], 'ab': ['l'], 'bl': ['y'], ' w': ['i', 'a'], 'wi': ['t'], 'it': ['h', ' '], 'th': [' ', 'e', 'o', 'e', ' ', 'e', 'e', '’'], 'h ': ['t', 't', 'h'], ' c': ['l', 'h', 'o'], 'cl': ['i'], 'li': ['m'], 'im': ['a'], 'ma': ['t', 'n'], 'at': ['e', 't', 'u', 'u'], 'e,': [' '], ', ': ['t'], 'ho': ['u'], 'ou': ['g', 'r'], 'ug': ['h'], 'gh': [' '], ' l': ['a'], 'la': ['t', 'n'], 'tt': ['e'], 'r ': ['r', 'p'], ' r': ['e'], 'ef': ['e', 'f'], 'fe': ['r', 'c'], 'rs': [' '], 'to': [' '], 'o ': ['\\n'], ' \\n': [' ', ' '], '\\n ': [' ', ' '], '  ': [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'b', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'I'], ' b': ['o'], 'bo': ['t'], 'ot': ['h'], ' h': ['u', 'a'], 'hu': ['m'], 'um': ['a'], 'n-': [' '], '- ': ['a'], ' a': ['n', 'n', 's', 'v'], 'nd': [' ', ' '], ' n': ['a'], 'na': ['t'], 'tu': ['r', 'r'], 'ur': ['a', ' ', 'e', 'f', 'e'], 'ra': ['l', 'g', 't'], 'al': ['l', ' '], 'll': ['y'], ' p': ['r', 'l'], 'pr': ['o'], 'ro': ['d'], 'od': ['u'], 'du': ['c'], 'uc': ['e'], 'ce': ['d', ' '], 'wa': ['r'], 'ar': ['m', 't'], 'mi': ['n'], 'g ': ['a'], ' e': ['f'], 'ff': ['e'], 'ec': ['t'], 'ct': ['s'], 'ts': [' '], 't ': ['h', 'i', 'c'], 'as': [' ', 'u', ' ', 'e'], ' o': ['n', 'u'], 'on': [' ', 'l'], 'n ': ['o', 'E'], 'pl': ['a'], 'ne': ['t'], 'et': ['.'], 't.': [' '], '. ': ['\\n'], ' I': ['t'], 'It': [' '], ' m': ['o', 'e'], 'mo': ['s', 'n'], 'os': ['t'], 'st': [' '], 'co': ['m'], 'om': ['m'], 'mm': ['o'], 'nl': ['y'], 'me': ['a'], 'su': ['r', 'r'], 'av': ['e'], 've': ['r'], 'ag': ['e'], 'nc': ['r'], 'cr': ['e'], ' E': ['a'], 'Ea': ['r'], 'rt': ['h'], 'h’': ['s'], '’s': [' '], ' g': ['l'], 'gl': ['o'], 'lo': ['b'], 'ob': ['a'], 'ba': ['l'], 'l ': ['s'], ' s': ['u'], 'rf': ['a'], 'fa': ['c'], 'ac': ['e'], 'em': ['p'], 'mp': ['e'], 'pe': ['r']}\n"
     ]
    }
   ],
   "source": [
    "print(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams1 = {}\n",
    "words = nltk.word_tokenize(text)\n",
    "for i in range(len(words)-n):\n",
    "    gram = ' '.join(words[i:i+n])\n",
    "    if gram not in ngrams1.keys():\n",
    "        ngrams1[gram] = []\n",
    "    ngrams1[gram].append(words[i+n])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'he term': ['is'], 'term is': ['frequently'], 'is frequently': ['used'], 'frequently used': ['interchangeably'], 'used interchangeably': ['with'], 'interchangeably with': ['the'], 'with the': ['term'], 'the term': ['climate'], 'term climate': ['change'], 'climate change': [','], 'change ,': ['though'], ', though': ['the'], 'though the': ['latter'], 'the latter': ['refers'], 'latter refers': ['to'], 'refers to': ['both'], 'to both': ['human-'], 'both human-': ['and'], 'human- and': ['naturally'], 'and naturally': ['produced'], 'naturally produced': ['warming'], 'produced warming': ['and'], 'warming and': ['the'], 'and the': ['effects'], 'the effects': ['it'], 'effects it': ['has'], 'it has': ['on'], 'has on': ['our'], 'on our': ['planet'], 'our planet': ['.'], 'planet .': ['It'], '. It': ['is'], 'It is': ['most'], 'is most': ['commonly'], 'most commonly': ['measured'], 'commonly measured': ['as'], 'measured as': ['the'], 'as the': ['average'], 'the average': ['increase'], 'average increase': ['in'], 'increase in': ['Earth'], 'in Earth': ['’'], 'Earth ’': ['s'], '’ s': ['global'], 's global': ['surface'], 'global surface': ['temperature'], 'surface temperature': ['.']}\n"
     ]
    }
   ],
   "source": [
    "print(ngrams1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Semantic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 10)\t0.3604707823245737\n",
      "  (0, 5)\t0.3604707823245737\n",
      "  (0, 9)\t0.3604707823245737\n",
      "  (0, 18)\t0.3604707823245737\n",
      "  (0, 20)\t0.29922170630677863\n",
      "  (0, 27)\t0.3604707823245737\n",
      "  (0, 25)\t0.25576479528730944\n",
      "  (0, 2)\t0.3604707823245737\n",
      "  (0, 35)\t0.25576479528730944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "#sample data\n",
    "dataset = [\"The amount of polution is increasing day by daya\",\n",
    "           \"The concert was just great\",\n",
    "           \"I Love to see Garden Ramsay Cook\",\n",
    "            \"Google is introducting a new technology\",\n",
    "            \"AI Robots are examples of great technology present to you\",\n",
    "            \"All of us were singing in the concert\",\n",
    "            \"We have Launch compaigns to stop pollution and global warming\"]\n",
    "\n",
    "dataset = [line.lower() for line in dataset]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "x = vectorizer.fit_transform(dataset)\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation :  The tfidf value of The is 0.3604707823245737. The 0 indicates the first row and 10 indicates the position of The. Similary for all the words for first document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 15)\t0.4213298560187446\n",
      "  (0, 21)\t0.5075738143811802\n",
      "  (0, 39)\t0.5075738143811802\n",
      "  (0, 7)\t0.4213298560187446\n",
      "  (0, 35)\t0.36013879374975194\n"
     ]
    }
   ],
   "source": [
    "print(x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation :  The tfidf value of The is 0.3604707823245737. The 0 indicates the first row and 10 indicates the position of The. Similary for all the words for first document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "concept 0 :\n",
      "('the', 0.37931274666161524)\n",
      "('concert', 0.3322524212584805)\n",
      "('of', 0.30297933562408524)\n",
      "('great', 0.2883406330890268)\n",
      "('just', 0.22747274585828073)\n",
      "('was', 0.22747274585828073)\n",
      "('is', 0.1938158804638517)\n",
      "('technology', 0.18182537167789728)\n",
      "('all', 0.17278996134480654)\n",
      "('in', 0.17278996134480654)\n",
      "\n",
      "concept 1 :\n",
      "('to', 0.3549401919583129)\n",
      "('technology', 0.23931386858616868)\n",
      "('cook', 0.21500250606772944)\n",
      "('garden', 0.21500250606772944)\n",
      "('love', 0.21500250606772944)\n",
      "('ramsay', 0.21500250606772944)\n",
      "('see', 0.21500250606772944)\n",
      "('google', 0.15506130357728057)\n",
      "('introducting', 0.15506130357728057)\n",
      "('new', 0.15506130357728057)\n",
      "\n",
      "concept 2 :\n",
      "('is', 0.3648279017955781)\n",
      "('google', 0.3151297909758329)\n",
      "('introducting', 0.3151297909758329)\n",
      "('new', 0.3151297909758329)\n",
      "('technology', 0.26764814808496595)\n",
      "('amount', 0.12437642265177631)\n",
      "('by', 0.12437642265177631)\n",
      "('day', 0.12437642265177631)\n",
      "('daya', 0.12437642265177631)\n",
      "('increasing', 0.12437642265177631)\n",
      "\n",
      "concept 3 :\n",
      "('and', 0.2549178847054724)\n",
      "('compaigns', 0.25491788470547233)\n",
      "('global', 0.25491788470547233)\n",
      "('have', 0.25491788470547233)\n",
      "('launch', 0.25491788470547233)\n",
      "('pollution', 0.25491788470547233)\n",
      "('stop', 0.25491788470547233)\n",
      "('warming', 0.25491788470547233)\n",
      "('we', 0.25491788470547233)\n",
      "('by', 0.1184017093822117)\n"
     ]
    }
   ],
   "source": [
    "lsa = TruncatedSVD(n_components = 4,n_iter=100) # we have taken the 4 components\n",
    "lsa.fit(x)\n",
    "\n",
    "\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i,comp in enumerate(lsa.components_):\n",
    "    componentTerms = zip(terms,comp)\n",
    "    sortedTerms = sorted(componentTerms,key=lambda x:x[1],reverse=True)\n",
    "    sortedTerms = sortedTerms[:10]\n",
    "    print(\"\\nconcept\",i,\":\")\n",
    "    for term in sortedTerms:\n",
    "        print(term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Synonyms and Antonyms using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "synonyms = []\n",
    "antonyms = []\n",
    "\n",
    "for syn in wordnet.synsets(\"good\"):\n",
    "    for s in syn.lemmas():\n",
    "        synonyms.append(s.name())\n",
    "        for a in s.antonyms():\n",
    "            antonyms.append(a.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'commodity', 'unspoiled', 'just', 'good', 'goodness', 'dependable', 'full', 'undecomposed', 'skilful', 'expert', 'right', 'in_force', 'trade_good', 'upright', 'skillful', 'estimable', 'honorable', 'well', 'practiced', 'safe', 'in_effect', 'near', 'unspoilt', 'dear', 'honest', 'soundly', 'proficient', 'beneficial', 'ripe', 'adept', 'salutary', 'effective', 'serious', 'respectable', 'sound', 'thoroughly', 'secure'}\n",
      "{'ill', 'badness', 'bad', 'evil', 'evilness'}\n"
     ]
    }
   ],
   "source": [
    "print(set(synonyms))\n",
    "print(set(antonyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
